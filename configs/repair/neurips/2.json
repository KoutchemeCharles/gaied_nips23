{   
    "name": "starcoder-1B_falcon",
    "save_dir": "TO_SPECIFY",
    "agent": {
        "path": "bigcode/starcoderbase-1b"
    },
    
    "dataset": {
        "name": "falconcode",
        "subset": "",
        "path": "TO_SPECIFY",
        "reprocess": false,
        "processing": {
            "remove_zero_passing": true,
            "select_last": true
        },
        "mapping": {
            "name": "refactory",
            "tool_path": "TO_SPECIFY",
            "remap": false
        }
    },
    "training": {
        "n_trials": 20,
        "wandb_hp_space": {
            "method": "bayes",
            "metric": {"name": "objective", "goal": "minimize"},
            "parameters": {
                "learning_rate": {"values": [5e-5]},
                "lr_scheduler_type": {"values": ["cosine"]},
                "num_train_epochs": {"values": [1, 2, 3]},
                "gradient_accumulation_steps": {"values": [1, 4]},  
                "per_device_train_batch_size": {"values": [4, 8]},        
                "fp16": {"value": [true]}
            },
            "early_terminate": {"type": "hyperband", "min_iter": 3}
          },
        "hyperparameters": {
            "num_train_epochs": 4,
            "per_device_train_batch_size": 8,
            "gradient_accumulation_steps": 4,
            "fp16": true
          },
        "search_best_genconfig": false,
        "total_ppo_epochs": 100,
        "ppo_config": {
            "batch_size": 16,
            "mini_batch_size": 1,
            "learning_rate":1e-5,
            "log_with": "wandb",
            "ppo_epochs": 1,
            "gradient_accumulation_steps": 4,
            "optimize_cuda_cache": true,
            "use_score_scaling":true, 
            "use_score_norm": true
        }
     },
    
    "heval_k": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    "seed": 32,
    "max_seq_length": 512
}